---
layout: about
title: about
permalink: /
subtitle: <a href='#'>Affiliations</a>. Address. Contacts. Moto. Etc.

profile:
  align: right
  image: prof_pic.jpg
  image_circular: false # crops the image to make it circular
  address: >
    <p>Kowloon Tong, Hong Kong SAR China</p>

news: true  # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true  # includes social icons at the bottom of the page
---


Dr. Zhang Xiaoyuan is set to graduate early in April 2025 from the Department of Computer Science at City University of Hong Kong. During his PhD, he was supervised by Chair Professor Zhang Qingfu, a leading figure in multi-objective optimization (IEEE Fellow). He has also maintained long-term collaborations with Professor Yang Yaodong’s team at Peking University and Professor Han Zhao’s team at the University of Illinois at Urbana-Champaign. Dr. Zhang obtained his Bachelor’s (2017) and Master’s (2020) degrees in Engineering from Shanghai Jiao Tong University, where he was advised by Professor Qi Chenkun.

Dr. Zhang’s research focuses on the theory, software implementation, and engineering applications of multi-objective optimization. He proposed the open-source software library LibMOON, the industry's first gradient-based multi-objective optimization library, capable of efficiently solving large-scale optimization problems with millions of parameters. His work was invited for presentation at multiple conferences and was published at the top-tier conference NeurIPS 2024. Additionally, he made significant theoretical contributions in Pareto set learning and, in collaboration with the Peking University team, was the first to apply Pareto set learning to large-scale model training with tens of billions of parameters. These results were also published at NeurIPS 2024.

Dr. Zhang has published seven papers in NeurIPS/ICML, including four as the first author (one as co-first author), along with one IEEE Transactions paper. Several other papers are currently under review.